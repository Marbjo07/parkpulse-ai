8484
2165
.\Python\Python310\lib\site-packages\torchvision\models\_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.
  warnings.warn(
Sequential(
  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (2): ReLU(inplace=True)
  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (5): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (6): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (3): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (4): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (5): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
  (7): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (2): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
  )
)
.\Python\Python310\lib\site-packages\torch\nn\modules\lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn('Lazy modules are a new feature under heavy development '
Net(
  (model): Sequential(
    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (5): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (6): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (7): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (8): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): LazyLinear(in_features=0, out_features=512, bias=True)
      (2): ReLU()
      (3): Linear(in_features=512, out_features=1, bias=True)
      (4): Sigmoid()
    )
  )
)
Adjusting learning rate of group 0 to 3.0000e-03.
Train Epoch: 0 Loss: 0.189020: 100%|█████████████████████████████████████████████████| 265/265 [02:54<00:00,  1.52it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:35<00:00,  1.87it/s]

Test set: Average loss: 0.1725

Adjusting learning rate of group 0 to 2.7000e-03.
Train Epoch: 1 Loss: 0.123602: 100%|█████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.46it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 17.22it/s]

Test set: Average loss: 0.1197

Adjusting learning rate of group 0 to 2.4300e-03.
Train Epoch: 2 Loss: 0.068565: 100%|█████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.41it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.76it/s]

Test set: Average loss: 0.1335

Adjusting learning rate of group 0 to 2.1870e-03.
Train Epoch: 3 Loss: 0.096542: 100%|█████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.40it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.83it/s]

Test set: Average loss: 0.1163

Adjusting learning rate of group 0 to 1.9683e-03.
Train Epoch: 4 Loss: 0.279626: 100%|█████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.40it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.83it/s]

Test set: Average loss: 0.1275

Adjusting learning rate of group 0 to 1.7715e-03.
Train Epoch: 5 Loss: 0.321073: 100%|█████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.40it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.56it/s]

Test set: Average loss: 0.1153

Adjusting learning rate of group 0 to 1.5943e-03.
Train Epoch: 6 Loss: 0.192189: 100%|█████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.38it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.79it/s]

Test set: Average loss: 0.1130

Adjusting learning rate of group 0 to 1.4349e-03.
Train Epoch: 7 Loss: 0.231327: 100%|█████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.39it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.72it/s]

Test set: Average loss: 0.1075

Adjusting learning rate of group 0 to 1.2914e-03.
Train Epoch: 8 Loss: 0.120526: 100%|█████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.40it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.70it/s]

Test set: Average loss: 0.1142

Adjusting learning rate of group 0 to 1.1623e-03.
Train Epoch: 9 Loss: 0.334155: 100%|█████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.40it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.99it/s]

Test set: Average loss: 0.1201

Adjusting learning rate of group 0 to 1.0460e-03.
Train Epoch: 10 Loss: 0.088623: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.41it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.69it/s]

Test set: Average loss: 0.0981

Adjusting learning rate of group 0 to 9.4143e-04.
Train Epoch: 11 Loss: 0.097922: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.40it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.68it/s]

Test set: Average loss: 0.0969

Adjusting learning rate of group 0 to 8.4729e-04.
Train Epoch: 12 Loss: 0.183900: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.40it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.63it/s]

Test set: Average loss: 0.0998

Adjusting learning rate of group 0 to 7.6256e-04.
Train Epoch: 13 Loss: 0.112565: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.39it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.18it/s]

Test set: Average loss: 0.1101

Adjusting learning rate of group 0 to 6.8630e-04.
Train Epoch: 14 Loss: 0.134770: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.40it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.67it/s]

Test set: Average loss: 0.1002

Adjusting learning rate of group 0 to 6.1767e-04.
Train Epoch: 15 Loss: 0.127934: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.40it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.66it/s]

Test set: Average loss: 0.0959

Adjusting learning rate of group 0 to 5.5591e-04.
Train Epoch: 16 Loss: 0.191325: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.39it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.90it/s]

Test set: Average loss: 0.1064

Adjusting learning rate of group 0 to 5.0032e-04.
Train Epoch: 17 Loss: 0.019299: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.41it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.96it/s]

Test set: Average loss: 0.0915

Adjusting learning rate of group 0 to 4.5028e-04.
Train Epoch: 18 Loss: 0.087559: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.41it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.86it/s]

Test set: Average loss: 0.0959

Adjusting learning rate of group 0 to 4.0526e-04.
Train Epoch: 19 Loss: 0.082891: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.40it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.77it/s]

Test set: Average loss: 0.0916

Adjusting learning rate of group 0 to 3.6473e-04.
Train Epoch: 20 Loss: 0.036605: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.42it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.98it/s]

Test set: Average loss: 0.0908

Train Epoch: 21 Loss: 0.178844: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.41it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.81it/s]

Test set: Average loss: 0.0993

Train Epoch: 22 Loss: 0.133986: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.41it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.80it/s]

Test set: Average loss: 0.0942

Train Epoch: 23 Loss: 0.110901: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.40it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.64it/s]

Test set: Average loss: 0.0892

Train Epoch: 24 Loss: 0.115557: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.39it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.75it/s]

Test set: Average loss: 0.0942

Train Epoch: 25 Loss: 0.101581: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.42it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.80it/s]

Test set: Average loss: 0.0934

Train Epoch: 26 Loss: 0.098380: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.42it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.19it/s]

Test set: Average loss: 0.0963

Train Epoch: 27 Loss: 0.146956: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.40it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.69it/s]

Test set: Average loss: 0.0945

Train Epoch: 28 Loss: 0.060656: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.41it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.55it/s]

Test set: Average loss: 0.0889

Train Epoch: 29 Loss: 0.104043: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.40it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.79it/s]

Test set: Average loss: 0.0901

Train Epoch: 30 Loss: 0.132132: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.40it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.83it/s]

Test set: Average loss: 0.0802

Train Epoch: 31 Loss: 0.085692: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.42it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.76it/s]

Test set: Average loss: 0.0900

Train Epoch: 32 Loss: 0.256374: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.40it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.64it/s]

Test set: Average loss: 0.0898

Train Epoch: 33 Loss: 0.171565: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.42it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.63it/s]

Test set: Average loss: 0.0851

Train Epoch: 34 Loss: 0.047660: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.40it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.72it/s]

Test set: Average loss: 0.0939

Train Epoch: 35 Loss: 0.105264: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.42it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.78it/s]

Test set: Average loss: 0.0828

Train Epoch: 36 Loss: 0.046482: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.41it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.56it/s]

Test set: Average loss: 0.0806

Train Epoch: 37 Loss: 0.102663: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.42it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.77it/s]

Test set: Average loss: 0.0877

Train Epoch: 38 Loss: 0.092753: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.41it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.60it/s]

Test set: Average loss: 0.0876

Train Epoch: 39 Loss: 0.123947: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.42it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.11it/s]

Test set: Average loss: 0.0930

Train Epoch: 40 Loss: 0.087259: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.42it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.92it/s]

Test set: Average loss: 0.0894

Train Epoch: 41 Loss: 0.054869: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.41it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.79it/s]

Test set: Average loss: 0.0817

Train Epoch: 42 Loss: 0.063417: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.40it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.75it/s]

Test set: Average loss: 0.0859

Train Epoch: 43 Loss: 0.019876: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.40it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.64it/s]

Test set: Average loss: 0.0828

Train Epoch: 44 Loss: 0.056362: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.41it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.75it/s]

Test set: Average loss: 0.0793

Train Epoch: 45 Loss: 0.094548: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.41it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.81it/s]

Test set: Average loss: 0.0913

Train Epoch: 46 Loss: 0.251936: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.40it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.88it/s]

Test set: Average loss: 0.0783

Train Epoch: 47 Loss: 0.048011: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.40it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.78it/s]

Test set: Average loss: 0.0856

Train Epoch: 48 Loss: 0.017267: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.41it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.83it/s]

Test set: Average loss: 0.0832

Train Epoch: 49 Loss: 0.012010: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.41it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.79it/s]

Test set: Average loss: 0.0882

Train Epoch: 50 Loss: 0.026982: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.42it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.77it/s]

Test set: Average loss: 0.0839

Train Epoch: 51 Loss: 0.029499: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.40it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.82it/s]

Test set: Average loss: 0.0834

Train Epoch: 52 Loss: 0.021829: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.40it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.40it/s]

Test set: Average loss: 0.0766

Train Epoch: 53 Loss: 0.088701: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.40it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.69it/s]

Test set: Average loss: 0.0835

Train Epoch: 54 Loss: 0.027384: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.41it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.26it/s]

Test set: Average loss: 0.0708

Train Epoch: 55 Loss: 0.095148: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.41it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.54it/s]

Test set: Average loss: 0.0909

Train Epoch: 56 Loss: 0.033735: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.40it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.80it/s]

Test set: Average loss: 0.0775

Train Epoch: 57 Loss: 0.082741: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.40it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.77it/s]

Test set: Average loss: 0.0900

Train Epoch: 58 Loss: 0.110386: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.40it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.65it/s]

Test set: Average loss: 0.0761

Train Epoch: 59 Loss: 0.078468: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.41it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.64it/s]

Test set: Average loss: 0.0759

Train Epoch: 60 Loss: 0.014644: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.41it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.55it/s]

Test set: Average loss: 0.0742

Train Epoch: 61 Loss: 0.008015: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.40it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.88it/s]

Test set: Average loss: 0.0885

Train Epoch: 62 Loss: 0.038356: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.40it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.87it/s]

Test set: Average loss: 0.0824

Train Epoch: 63 Loss: 0.030393: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.41it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.83it/s]

Test set: Average loss: 0.0769

Train Epoch: 64 Loss: 0.094828: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.42it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.84it/s]

Test set: Average loss: 0.0747

Train Epoch: 65 Loss: 0.019429: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.41it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.72it/s]

Test set: Average loss: 0.0755

Train Epoch: 66 Loss: 0.055406: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.40it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.71it/s]

Test set: Average loss: 0.0789

Train Epoch: 67 Loss: 0.052372: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.42it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.68it/s]

Test set: Average loss: 0.0805

Train Epoch: 68 Loss: 0.044014: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.42it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.53it/s]

Test set: Average loss: 0.0755

Train Epoch: 69 Loss: 0.007766: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.41it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.70it/s]

Test set: Average loss: 0.0804

Train Epoch: 70 Loss: 0.062719: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.42it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.75it/s]

Test set: Average loss: 0.0699

Train Epoch: 71 Loss: 0.014796: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.41it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.53it/s]

Test set: Average loss: 0.0785

Train Epoch: 72 Loss: 0.026233: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.42it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.98it/s]

Test set: Average loss: 0.0728

Train Epoch: 73 Loss: 0.036569: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.40it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.19it/s]

Test set: Average loss: 0.0728

Train Epoch: 74 Loss: 0.011489: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.41it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.73it/s]

Test set: Average loss: 0.0717

Train Epoch: 75 Loss: 0.071997: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.42it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.84it/s]

Test set: Average loss: 0.0670

Train Epoch: 76 Loss: 0.093358: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.40it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.76it/s]

Test set: Average loss: 0.0755

Train Epoch: 77 Loss: 0.040345: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.40it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.79it/s]

Test set: Average loss: 0.0760

Train Epoch: 78 Loss: 0.022909: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.42it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.73it/s]

Test set: Average loss: 0.0717

Train Epoch: 79 Loss: 0.002938: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.41it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.66it/s]

Test set: Average loss: 0.0683

Train Epoch: 80 Loss: 0.023009: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.41it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.46it/s]

Test set: Average loss: 0.0723

Train Epoch: 81 Loss: 0.009298: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.39it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.78it/s]

Test set: Average loss: 0.0725

Train Epoch: 82 Loss: 0.016463: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.41it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.89it/s]

Test set: Average loss: 0.0694

Train Epoch: 83 Loss: 0.022854: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.42it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.60it/s]

Test set: Average loss: 0.0681

Train Epoch: 84 Loss: 0.008153: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.41it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.75it/s]

Test set: Average loss: 0.0741

Train Epoch: 85 Loss: 0.003903: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.41it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.73it/s]

Test set: Average loss: 0.0755

Train Epoch: 86 Loss: 0.000224: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.39it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.09it/s]

Test set: Average loss: 0.0700

Train Epoch: 87 Loss: 0.017691: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.40it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.75it/s]

Test set: Average loss: 0.0728

Train Epoch: 88 Loss: 0.003290: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.40it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.80it/s]

Test set: Average loss: 0.0723

Train Epoch: 89 Loss: 0.009395: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.39it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.70it/s]

Test set: Average loss: 0.0660

Train Epoch: 90 Loss: 0.004105: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.41it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.64it/s]

Test set: Average loss: 0.0796

Train Epoch: 91 Loss: 0.007219: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.42it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.76it/s]

Test set: Average loss: 0.0703

Train Epoch: 92 Loss: 0.005974: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.40it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.46it/s]

Test set: Average loss: 0.0669

Train Epoch: 93 Loss: 0.017962: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.41it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.84it/s]

Test set: Average loss: 0.0672

Train Epoch: 94 Loss: 0.000845: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.42it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.66it/s]

Test set: Average loss: 0.0705

Train Epoch: 95 Loss: 0.031698: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.41it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.81it/s]

Test set: Average loss: 0.0684

Train Epoch: 96 Loss: 0.012061: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.42it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.91it/s]

Test set: Average loss: 0.0728

Train Epoch: 97 Loss: 0.012325: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.41it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.95it/s]

Test set: Average loss: 0.0677

Train Epoch: 98 Loss: 0.070358: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.41it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.85it/s]

Test set: Average loss: 0.0720

Train Epoch: 99 Loss: 0.001269: 100%|████████████████████████████████████████████████| 265/265 [00:18<00:00, 14.41it/s]
100%|██████████████████████████████████████████████████████████████████████████████████| 67/67 [00:03<00:00, 18.19it/s]

Test set: Average loss: 0.0714